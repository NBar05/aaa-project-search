{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q numpy pandas tqdm pymystem3 tensorflow torch transformers qdrant-client ranx","metadata":{"execution":{"iopub.status.busy":"2023-06-06T20:36:43.516929Z","iopub.execute_input":"2023-06-06T20:36:43.517324Z","iopub.status.idle":"2023-06-06T20:37:28.914999Z","shell.execute_reply.started":"2023-06-06T20:36:43.517288Z","shell.execute_reply":"2023-06-06T20:37:28.913553Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndask-cudf 21.12.2 requires cupy-cuda115, which is not installed.\ncudf 21.12.2 requires cupy-cuda115, which is not installed.\nxarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.20.3 which is incompatible.\ntfx-bsl 1.12.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.79.0 which is incompatible.\ntfx-bsl 1.12.0 requires pyarrow<7,>=6, but you have pyarrow 5.0.0 which is incompatible.\ntensorflow-transform 1.12.0 requires pyarrow<7,>=6, but you have pyarrow 5.0.0 which is incompatible.\nonnx 1.13.1 requires protobuf<4,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\nlibrosa 0.10.0 requires soundfile>=0.12.1, but you have soundfile 0.11.0 which is incompatible.\nfeaturetools 1.11.1 requires numpy>=1.21.0, but you have numpy 1.20.3 which is incompatible.\ndask-cudf 21.12.2 requires dask<=2021.11.2,>=2021.11.1, but you have dask 2022.2.0 which is incompatible.\ncmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.20.3 which is incompatible.\napache-beam 2.44.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nfrom torch import nn, optim\n\nfrom transformers import AutoTokenizer, AutoModel\nfrom transformers import logging\nlogging.set_verbosity_error()\n\nfrom functools import partial\n\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.http.models import Distance, VectorParams, PointStruct\nfrom qdrant_client.http.models import CollectionStatus\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport nltk\nnltk.download(\"stopwords\")\nfrom nltk.corpus import stopwords\nfrom pymystem3 import Mystem\nfrom string import punctuation\n\nfrom ranx import Qrels, Run, evaluate, compare\n\nfrom tqdm import tqdm\nfrom copy import deepcopy\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\nDIR = '/kaggle/input/aaa-project-search/'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-06T20:37:28.918687Z","iopub.execute_input":"2023-06-06T20:37:28.919891Z","iopub.status.idle":"2023-06-06T20:37:42.193208Z","shell.execute_reply.started":"2023-06-06T20:37:28.919837Z","shell.execute_reply":"2023-06-06T20:37:42.191874Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\ncuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_hdf(DIR + 'search_relevance_dataset_v1.hdf', 'table')\ndf.drop(columns=['query_category_id', 'query_microcat_id', 'query_location_id'], inplace=True)\n\ndf.query_id = df.query_id.astype(str)\ndf.item_id = df.item_id.astype(str)\n\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T20:37:42.195056Z","iopub.execute_input":"2023-06-06T20:37:42.196890Z","iopub.status.idle":"2023-06-06T20:37:47.522472Z","shell.execute_reply.started":"2023-06-06T20:37:42.196833Z","shell.execute_reply":"2023-06-06T20:37:47.520317Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"  query_id query_text    item_id  \\\n0   274025  2108 ссср  964140459   \n1   274025  2108 ссср  990433426   \n2   274025  2108 ссср  994402610   \n\n                                               title  \\\n0  Советские бутыли канистры 60-80-х СССР ваз газ...   \n1        Ваз 2108 СССР цвет салатовый 1/43 идеальный   \n2   Модели советских машин ваз 2102 почта М 1/43 №10   \n\n                                         description         keywords  target  \n0  Для ценителей и понимающих.\\n\\nПодробные фотог...   стопсфинксstop       0  \n1  красивый салатовый цвет\\nвсе детали в наличии\\...           модель       1  \n2  Продается модель автомобиля  ВАЗ 2102 почта . ...           модель       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>query_id</th>\n      <th>query_text</th>\n      <th>item_id</th>\n      <th>title</th>\n      <th>description</th>\n      <th>keywords</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>274025</td>\n      <td>2108 ссср</td>\n      <td>964140459</td>\n      <td>Советские бутыли канистры 60-80-х СССР ваз газ...</td>\n      <td>Для ценителей и понимающих.\\n\\nПодробные фотог...</td>\n      <td>стопсфинксstop</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>274025</td>\n      <td>2108 ссср</td>\n      <td>990433426</td>\n      <td>Ваз 2108 СССР цвет салатовый 1/43 идеальный</td>\n      <td>красивый салатовый цвет\\nвсе детали в наличии\\...</td>\n      <td>модель</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>274025</td>\n      <td>2108 ссср</td>\n      <td>994402610</td>\n      <td>Модели советских машин ваз 2102 почта М 1/43 №10</td>\n      <td>Продается модель автомобиля  ВАЗ 2102 почта . ...</td>\n      <td>модель</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Create lemmatizer and stopwords list\nmystem = Mystem() \nrussian_stopwords = stopwords.words('russian')\n\n# Preprocess function\ndef preprocess_text(text):\n    text = ' '.join(text.lower().split())\n\n#     tokens = mystem.lemmatize(text)\n#     tokens = [token for token in tokens if token not in russian_stopwords\\\n#               and token != ' ' and token.strip() not in punctuation]\n\n#     text = ' '.join(tokens)\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2023-06-06T20:37:47.524279Z","iopub.execute_input":"2023-06-06T20:37:47.525038Z","iopub.status.idle":"2023-06-06T20:37:52.221450Z","shell.execute_reply.started":"2023-06-06T20:37:47.524990Z","shell.execute_reply":"2023-06-06T20:37:52.220120Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n","output_type":"stream"}]},{"cell_type":"code","source":"df.query_text = df.query_text.apply(preprocess_text)\ndf.title = df.title.apply(preprocess_text)\n\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T20:37:52.225858Z","iopub.execute_input":"2023-06-06T20:37:52.226619Z","iopub.status.idle":"2023-06-06T20:37:52.757227Z","shell.execute_reply.started":"2023-06-06T20:37:52.226570Z","shell.execute_reply":"2023-06-06T20:37:52.756113Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"  query_id query_text    item_id  \\\n0   274025  2108 ссср  964140459   \n1   274025  2108 ссср  990433426   \n2   274025  2108 ссср  994402610   \n\n                                               title  \\\n0  советские бутыли канистры 60-80-х ссср ваз газ...   \n1        ваз 2108 ссср цвет салатовый 1/43 идеальный   \n2   модели советских машин ваз 2102 почта м 1/43 №10   \n\n                                         description         keywords  target  \n0  Для ценителей и понимающих.\\n\\nПодробные фотог...   стопсфинксstop       0  \n1  красивый салатовый цвет\\nвсе детали в наличии\\...           модель       1  \n2  Продается модель автомобиля  ВАЗ 2102 почта . ...           модель       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>query_id</th>\n      <th>query_text</th>\n      <th>item_id</th>\n      <th>title</th>\n      <th>description</th>\n      <th>keywords</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>274025</td>\n      <td>2108 ссср</td>\n      <td>964140459</td>\n      <td>советские бутыли канистры 60-80-х ссср ваз газ...</td>\n      <td>Для ценителей и понимающих.\\n\\nПодробные фотог...</td>\n      <td>стопсфинксstop</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>274025</td>\n      <td>2108 ссср</td>\n      <td>990433426</td>\n      <td>ваз 2108 ссср цвет салатовый 1/43 идеальный</td>\n      <td>красивый салатовый цвет\\nвсе детали в наличии\\...</td>\n      <td>модель</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>274025</td>\n      <td>2108 ссср</td>\n      <td>994402610</td>\n      <td>модели советских машин ваз 2102 почта м 1/43 №10</td>\n      <td>Продается модель автомобиля  ВАЗ 2102 почта . ...</td>\n      <td>модель</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"client = QdrantClient(':memory:')","metadata":{"execution":{"iopub.status.busy":"2023-06-06T20:37:52.760754Z","iopub.execute_input":"2023-06-06T20:37:52.761080Z","iopub.status.idle":"2023-06-06T20:37:52.766315Z","shell.execute_reply.started":"2023-06-06T20:37:52.761050Z","shell.execute_reply":"2023-06-06T20:37:52.765101Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def index_dataset(client, df, model, vector_size, collection_name='collection'):\n    client.recreate_collection(\n        collection_name=collection_name, vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE),\n    )\n    df = df.drop_duplicates(subset=['item_id'])\n\n    points = []\n    for row in tqdm(df.itertuples(), total=len(df)):\n        points.append(\n            PointStruct(\n                id=row.Index,\n                vector=list(map(float, model(row.title))), # list(map(float.. to make proper type\n                payload={\n                    'title': row.title, 'description': row.description, 'keywords': row.keywords, 'item_id': row.item_id\n                },\n            )\n        )\n\n    operation_info = client.upsert(collection_name=collection_name, wait=True, points=points)\n\n    return operation_info","metadata":{"execution":{"iopub.status.busy":"2023-06-06T20:37:52.768284Z","iopub.execute_input":"2023-06-06T20:37:52.769133Z","iopub.status.idle":"2023-06-06T20:37:52.780284Z","shell.execute_reply.started":"2023-06-06T20:37:52.769092Z","shell.execute_reply":"2023-06-06T20:37:52.779075Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# random model\nrandom_model = lambda text: np.random.randn(32)\n\n# baseline model 1\ntokenizer = AutoTokenizer.from_pretrained('cointegrated/rubert-tiny2')\nmodel = AutoModel.from_pretrained('cointegrated/rubert-tiny2').to(device)\n\ndef embed_bert_cls(text, model, tokenizer):\n    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n    with torch.no_grad():\n        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n    embeddings = model_output.last_hidden_state[:, 0, :]\n    embeddings = torch.nn.functional.normalize(embeddings)\n    return embeddings[0].cpu().numpy()\n\nbaseline_model_1 = partial(embed_bert_cls, model=model, tokenizer=tokenizer)\n\n# baseline model 2\ntokenizer = AutoTokenizer.from_pretrained('cointegrated/LaBSE-en-ru')\nmodel = AutoModel.from_pretrained('cointegrated/LaBSE-en-ru').to(device)\n\ndef embed_labse_cls(text, model, tokenizer):\n    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n    with torch.no_grad():\n        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n    embeddings = model_output.pooler_output\n    embeddings = torch.nn.functional.normalize(embeddings)\n    return embeddings[0].cpu().numpy()\n\nbaseline_model_2 = partial(embed_labse_cls, model=model, tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T20:37:52.782193Z","iopub.execute_input":"2023-06-06T20:37:52.782719Z","iopub.status.idle":"2023-06-06T20:38:11.305109Z","shell.execute_reply.started":"2023-06-06T20:37:52.782675Z","shell.execute_reply":"2023-06-06T20:38:11.303715Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/401 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3016fbcb1bec4029a8669659b341ba19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d16bb3754f5143138df7305e223f8525"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.74M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f24ba1c2d3248818019c0b2021c33fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fca57c4a366c499daf17a7444a4db850"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/715 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"271c7d3740dd4006a66048657408a4f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/118M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"426195bdbd8b4ae3a74fa6946d40d368"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9dac7f6c3a04ab69c7d7a008cfd10f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6e2f88afb314f11b96c7a1b55b1857e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/521k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"676279c2c01f4014987d768544aad5bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6814f866023548cab0d541dc823f3c38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/516M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7249cd51f4bd48298466e08c68b2196e"}},"metadata":{}}]},{"cell_type":"code","source":"baseline_model_1('hello').shape, baseline_model_2('hello').shape # ((312,), (768,))","metadata":{"execution":{"iopub.status.busy":"2023-06-06T20:38:11.307164Z","iopub.execute_input":"2023-06-06T20:38:11.308047Z","iopub.status.idle":"2023-06-06T20:38:12.914671Z","shell.execute_reply.started":"2023-06-06T20:38:11.307986Z","shell.execute_reply":"2023-06-06T20:38:12.912826Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"((312,), (768,))"},"metadata":{}}]},{"cell_type":"code","source":"class ProjectorModel(nn.Module):\n    def __init__(self, model_name: str = 'cointegrated/rubert-tiny2', final_emb_size: int = 32):\n        super().__init__()\n\n        self.model_name = model_name\n        self.final_emb_size = final_emb_size\n        \n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n        self.backbone = AutoModel.from_pretrained(self.model_name, output_hidden_states=True).to(device)\n\n        for n, p in self.backbone.named_parameters():\n            p.requires_grad = False\n\n        self.initial_emd_size = 312 if self.model_name == 'cointegrated/rubert-tiny2' else 768\n\n        self.projection_head = nn.Sequential(\n            nn.Linear(self.initial_emd_size, self.final_emb_size, device=device),            \n        )\n\n    def backbone_forward(self, text):\n        t = self.tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n        model_output = self.backbone(**{k: v.to(self.backbone.device) for k, v in t.items()})\n\n#         embeddings = model_output.pooler_output # torch.concat([model_output['hidden_states'][-i].mean(dim=1) for i in range(1, 5, 1)], dim=1)\n\n        embeddings = model_output.last_hidden_state[:, 0, :] if self.model_name == 'cointegrated/rubert-tiny2' else model_output.pooler_output\n        embeddings = nn.functional.normalize(embeddings)\n\n        return embeddings\n\n    def forward(self, text):\n        embeddings = self.backbone_forward(text)\n\n        compressed_embeddings = self.projection_head(embeddings)\n        compressed_embeddings = nn.functional.normalize(compressed_embeddings)\n\n        return compressed_embeddings\n\nProjectorModel()('some text here').shape, ProjectorModel()(['some text here', 'lalala']).shape","metadata":{"execution":{"iopub.status.busy":"2023-06-06T20:38:12.917087Z","iopub.execute_input":"2023-06-06T20:38:12.918296Z","iopub.status.idle":"2023-06-06T20:38:14.833611Z","shell.execute_reply.started":"2023-06-06T20:38:12.918243Z","shell.execute_reply":"2023-06-06T20:38:14.832420Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(torch.Size([1, 32]), torch.Size([2, 32]))"},"metadata":{}}]},{"cell_type":"code","source":"def train_eval(model, df_train, df_test, batch_size=64, n_epochs=5, lr=1e-5):\n    model.train()\n\n    queries = df_train.query_id.unique()\n    df_train = df_train.set_index('query_id')\n\n    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-3)\n\n    for e in range(n_epochs):\n        train_set = df_train.loc[np.random.choice(queries, size=len(queries), replace=False), ['query_text', 'title', 'target', 'query_len', 'keywords']].values\n        num_batches = len(train_set) // batch_size\n\n        for i in tqdm(range(num_batches)):\n            start, end = i * batch_size, (i + 1) * batch_size\n            batch = train_set[start:end]\n\n            x1, x2, y = list(batch[:, 0]), list(batch[:, 1]), torch.tensor(batch[:, 2].astype(int), device=device)\n\n            loss = 0.5 * ((y - (model.backbone_forward(x1) * model.backbone_forward(x2)).sum(dim=1))**2).mean() +\\\n                   0.5 * ((y - (model(x1) * model(x2)).sum(dim=1))**2).mean()\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            optimizer.step()\n            optimizer.zero_grad()\n\n        if e == 0:\n            for n, p in model.named_parameters():\n                if n[:5] != 'embed':\n                    p.requires_grad = True\n\n            optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n\n        model.eval()\n\n        test_set = df_test.loc[:, ['query_text', 'title', 'target', 'query_len', 'keywords']].values\n        num_batches = len(test_set) // batch_size\n\n        pred1, pred2, true = [], [], []\n        for i in tqdm(range(num_batches + 1)):\n            start, end = i * batch_size, (i + 1) * batch_size\n            batch = test_set[start:end]\n\n            x1, x2, y = list(batch[:, 0]), list(batch[:, 1]), batch[:, 2].astype(int)\n\n            pred1.extend((model.backbone_forward(x1) * model.backbone_forward(x2)).sum(dim=1).abs().cpu().detach().numpy())\n            pred2.extend((model(x1) * model(x2)).sum(dim=1).abs().cpu().detach().numpy())\n            true.extend(y)\n\n        print(f'Epoch {e}:')\n        print(f'Test ROC-AUC backbone: {roc_auc_score(true, pred1):.3f}')\n        print(f'Test ROC-AUC full net: {roc_auc_score(true, pred2):.3f}')\n\n        df_test['true'] = true\n        df_test['pred1'] = pred1\n        df_test['pred2'] = pred2\n\n        print('Test ROC-AUC by query length:')\n        display(df_test.groupby('query_len').apply(\n            lambda d: [f'{roc_auc_score(d.true, d.pred1):.3f}', f'{roc_auc_score(d.true, d.pred2):.3f}']\n        ))\n\n        model.train()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T20:38:14.835468Z","iopub.execute_input":"2023-06-06T20:38:14.836459Z","iopub.status.idle":"2023-06-06T20:38:14.861497Z","shell.execute_reply.started":"2023-06-06T20:38:14.836411Z","shell.execute_reply":"2023-06-06T20:38:14.860121Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df['query_len'] = df['query_text'].apply(lambda x: len(x.split(' ')))\ndf.loc[df.query_len > 3, 'query_len'] = 3\ndf.query_len.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T20:38:14.863374Z","iopub.execute_input":"2023-06-06T20:38:14.864181Z","iopub.status.idle":"2023-06-06T20:38:17.284764Z","shell.execute_reply.started":"2023-06-06T20:38:14.864132Z","shell.execute_reply":"2023-06-06T20:38:17.283456Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"3    62688\n2    62398\n1    36343\nName: query_len, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.title = 'объявление: ' + df.title\ndf.query_text = 'запрос: ' + df.query_text\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T20:42:20.960314Z","iopub.execute_input":"2023-06-06T20:42:20.960874Z","iopub.status.idle":"2023-06-06T20:42:21.082247Z","shell.execute_reply.started":"2023-06-06T20:42:20.960836Z","shell.execute_reply":"2023-06-06T20:42:21.080919Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"  query_id         query_text     item_id  \\\n0   274025  запрос: 2108 ссср   964140459   \n1   274025  запрос: 2108 ссср   990433426   \n2   274025  запрос: 2108 ссср   994402610   \n3   274025  запрос: 2108 ссср  1069135877   \n4   274025  запрос: 2108 ссср  1217235061   \n\n                                               title  \\\n0  объявление: советские бутыли канистры 60-80-х ...   \n1  объявление: ваз 2108 ссср цвет салатовый 1/43 ...   \n2  объявление: модели советских машин ваз 2102 по...   \n3         объявление: книга автомобиль ваз-2108 ссср   \n4      объявление: плакаты, ваз 2108, ссср, 1988 год   \n\n                                         description             keywords  \\\n0  Для ценителей и понимающих.\\n\\nПодробные фотог...       стопсфинксstop   \n1  красивый салатовый цвет\\nвсе детали в наличии\\...               модель   \n2  Продается модель автомобиля  ВАЗ 2102 почта . ...               модель   \n3  Спутник СССР ВАЗ устройство автомобиля 2108 19...   учебный литература   \n4  Продам комплект плакатов по устройству автомоб...   учебный литература   \n\n   target  query_len  \n0       0          2  \n1       1          2  \n2       1          2  \n3       1          2  \n4       0          2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>query_id</th>\n      <th>query_text</th>\n      <th>item_id</th>\n      <th>title</th>\n      <th>description</th>\n      <th>keywords</th>\n      <th>target</th>\n      <th>query_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>274025</td>\n      <td>запрос: 2108 ссср</td>\n      <td>964140459</td>\n      <td>объявление: советские бутыли канистры 60-80-х ...</td>\n      <td>Для ценителей и понимающих.\\n\\nПодробные фотог...</td>\n      <td>стопсфинксstop</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>274025</td>\n      <td>запрос: 2108 ссср</td>\n      <td>990433426</td>\n      <td>объявление: ваз 2108 ссср цвет салатовый 1/43 ...</td>\n      <td>красивый салатовый цвет\\nвсе детали в наличии\\...</td>\n      <td>модель</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>274025</td>\n      <td>запрос: 2108 ссср</td>\n      <td>994402610</td>\n      <td>объявление: модели советских машин ваз 2102 по...</td>\n      <td>Продается модель автомобиля  ВАЗ 2102 почта . ...</td>\n      <td>модель</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>274025</td>\n      <td>запрос: 2108 ссср</td>\n      <td>1069135877</td>\n      <td>объявление: книга автомобиль ваз-2108 ссср</td>\n      <td>Спутник СССР ВАЗ устройство автомобиля 2108 19...</td>\n      <td>учебный литература</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>274025</td>\n      <td>запрос: 2108 ссср</td>\n      <td>1217235061</td>\n      <td>объявление: плакаты, ваз 2108, ссср, 1988 год</td>\n      <td>Продам комплект плакатов по устройству автомоб...</td>\n      <td>учебный литература</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"%%time\n\nkf = GroupKFold(n_splits=2)\n\nfor train_indices, test_indices in kf.split(X=df, groups=df.query_id):    \n    df_train, df_test = df.loc[train_indices], df.loc[test_indices]\n    print('-' * 80)\n    print('Train:', df_train.shape, df_train.query_id.nunique(), '  ',\n          'Test:', df_test.shape, df_test.query_id.nunique(), '  ',\n          'Intersection:', set(df_train.query_id).intersection(set(df_test.query_id)))\n    print()\n\n    runs = []\n    for model_name in ['cointegrated/rubert-tiny2']: # ['cointegrated/rubert-tiny2', 'cointegrated/LaBSE-en-ru']:\n        for final_emb_size in [64]:\n            print('Processing...', model_name, final_emb_size)\n\n            model = ProjectorModel(model_name=model_name, final_emb_size=final_emb_size)\n            train_eval(model, df_train, df_test, batch_size=512, n_epochs=1+15, lr=1e-5)\n\n            model.eval()\n\n            final_model = lambda text: model(text).cpu().detach().numpy()[0]\n            _ = index_dataset(client, df, final_model, vector_size=final_emb_size,\n                              collection_name=f'train_collection_{model_name}_{final_emb_size}')\n\n            qrels = Qrels.from_df(df_test, q_id_col='query_id', doc_id_col='item_id', score_col='target')\n            test_examples = df_test.drop_duplicates(subset=['query_id', 'query_text']).loc[:, ['query_id', 'query_text']]\n\n            run_dict = {}\n            for row in tqdm(test_examples.itertuples(), total=len(test_examples)):\n                search_result = client.search(\n                    collection_name=f'train_collection_{model_name}_{final_emb_size}', \n                    query_vector=list(map(float, final_model(row.query_text))), limit=50\n                )\n                run_dict[row.query_id] = {i.payload['item_id']: i.score for i in search_result}\n\n            run = Run(run_dict) # print(evaluate(qrels, run, ['map@10', 'map@50', 'ndcg@10', 'ndcg@50']))\n            runs.append(run)\n\n            client.delete_collection(collection_name=f'train_collection_{model_name}_{final_emb_size}')\n            print('Done')\n\n    report = compare(\n        qrels=qrels, runs=runs,\n        metrics=['map@10', 'map@50', 'ndcg@10', 'ndcg@50'],\n        n_permutations=1000, stat_test='student', max_p=0.01,\n    )\n    print(); print(report); print()\n\n    break\n\n# 0.752 - base\n# 0.788-0.789 8-9 epochs - new loss\n# 0.790 8-9 epochs - normalize both\n\n# 0.789 (0.803 backbone) 9-11 epochs - 1/1 loss\n# 0.791-0.792 (0.804-0.805 backbone) 10-11 epochs - 0.5 / 0.5 loss (batch 256 as I remember)\n\n# 0.805 (0.806 backbone) - 10 epochs - lowercase preprocessing\n# 0.805 (0.813 backbone) - 15 epochs - special tokens prior","metadata":{"execution":{"iopub.status.busy":"2023-06-06T20:42:55.320712Z","iopub.execute_input":"2023-06-06T20:42:55.321541Z","iopub.status.idle":"2023-06-06T21:28:20.299964Z","shell.execute_reply.started":"2023-06-06T20:42:55.321498Z","shell.execute_reply":"2023-06-06T21:28:20.298658Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"--------------------------------------------------------------------------------\nTrain: (80714, 8) 6172    Test: (80715, 8) 6173    Intersection: set()\n\nProcessing... cointegrated/rubert-tiny2 64\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 157/157 [00:24<00:00,  6.53it/s]\n100%|██████████| 158/158 [00:27<00:00,  5.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0:\nTest ROC-AUC backbone: 0.667\nTest ROC-AUC full net: 0.657\nTest ROC-AUC by query length:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"query_len\n1    [0.687, 0.677]\n2    [0.648, 0.633]\n3    [0.702, 0.692]\ndtype: object"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 157/157 [00:47<00:00,  3.30it/s]\n100%|██████████| 158/158 [00:26<00:00,  5.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1:\nTest ROC-AUC backbone: 0.739\nTest ROC-AUC full net: 0.734\nTest ROC-AUC by query length:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"query_len\n1    [0.755, 0.746]\n2    [0.705, 0.695]\n3    [0.778, 0.772]\ndtype: object"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 157/157 [00:47<00:00,  3.34it/s]\n100%|██████████| 158/158 [00:26<00:00,  5.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2:\nTest ROC-AUC backbone: 0.760\nTest ROC-AUC full net: 0.759\nTest ROC-AUC by query length:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"query_len\n1    [0.769, 0.760]\n2    [0.725, 0.722]\n3    [0.796, 0.793]\ndtype: object"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 157/157 [00:46<00:00,  3.36it/s]\n100%|██████████| 158/158 [00:26<00:00,  5.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3:\nTest ROC-AUC backbone: 0.771\nTest ROC-AUC full net: 0.769\nTest ROC-AUC by query length:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"query_len\n1    [0.773, 0.765]\n2    [0.736, 0.735]\n3    [0.805, 0.802]\ndtype: object"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 157/157 [00:47<00:00,  3.33it/s]\n100%|██████████| 158/158 [00:27<00:00,  5.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4:\nTest ROC-AUC backbone: 0.780\nTest ROC-AUC full net: 0.779\nTest ROC-AUC by query length:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"query_len\n1    [0.781, 0.772]\n2    [0.747, 0.747]\n3    [0.812, 0.809]\ndtype: object"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 157/157 [00:46<00:00,  3.37it/s]\n100%|██████████| 158/158 [00:26<00:00,  5.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5:\nTest ROC-AUC backbone: 0.786\nTest ROC-AUC full net: 0.784\nTest ROC-AUC by query length:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"query_len\n1    [0.784, 0.775]\n2    [0.755, 0.753]\n3    [0.818, 0.815]\ndtype: object"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 157/157 [00:46<00:00,  3.37it/s]\n100%|██████████| 158/158 [00:26<00:00,  5.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6:\nTest ROC-AUC backbone: 0.789\nTest ROC-AUC full net: 0.784\nTest ROC-AUC by query length:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"query_len\n1    [0.782, 0.773]\n2    [0.760, 0.755]\n3    [0.822, 0.818]\ndtype: object"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 157/157 [00:46<00:00,  3.36it/s]\n100%|██████████| 158/158 [00:26<00:00,  5.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7:\nTest ROC-AUC backbone: 0.798\nTest ROC-AUC full net: 0.795\nTest ROC-AUC by query length:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"query_len\n1    [0.792, 0.782]\n2    [0.768, 0.766]\n3    [0.828, 0.824]\ndtype: object"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 157/157 [00:46<00:00,  3.38it/s]\n100%|██████████| 158/158 [00:26<00:00,  5.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8:\nTest ROC-AUC backbone: 0.801\nTest ROC-AUC full net: 0.796\nTest ROC-AUC by query length:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"query_len\n1    [0.791, 0.779]\n2    [0.774, 0.770]\n3    [0.831, 0.827]\ndtype: object"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 157/157 [00:46<00:00,  3.40it/s]\n100%|██████████| 158/158 [00:26<00:00,  5.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9:\nTest ROC-AUC backbone: 0.800\nTest ROC-AUC full net: 0.794\nTest ROC-AUC by query length:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"query_len\n1    [0.787, 0.775]\n2    [0.774, 0.767]\n3    [0.832, 0.827]\ndtype: object"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 157/157 [00:47<00:00,  3.32it/s]\n100%|██████████| 158/158 [00:27<00:00,  5.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10:\nTest ROC-AUC backbone: 0.806\nTest ROC-AUC full net: 0.801\nTest ROC-AUC by query length:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"query_len\n1    [0.794, 0.783]\n2    [0.779, 0.774]\n3    [0.835, 0.831]\ndtype: object"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 157/157 [00:46<00:00,  3.35it/s]\n100%|██████████| 158/158 [00:27<00:00,  5.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11:\nTest ROC-AUC backbone: 0.808\nTest ROC-AUC full net: 0.803\nTest ROC-AUC by query length:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"query_len\n1    [0.794, 0.783]\n2    [0.782, 0.776]\n3    [0.838, 0.833]\ndtype: object"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 157/157 [00:47<00:00,  3.32it/s]\n100%|██████████| 158/158 [00:26<00:00,  6.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12:\nTest ROC-AUC backbone: 0.809\nTest ROC-AUC full net: 0.803\nTest ROC-AUC by query length:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"query_len\n1    [0.794, 0.781]\n2    [0.784, 0.775]\n3    [0.840, 0.834]\ndtype: object"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 157/157 [00:47<00:00,  3.34it/s]\n100%|██████████| 158/158 [00:27<00:00,  5.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13:\nTest ROC-AUC backbone: 0.807\nTest ROC-AUC full net: 0.798\nTest ROC-AUC by query length:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"query_len\n1    [0.788, 0.774]\n2    [0.783, 0.773]\n3    [0.840, 0.833]\ndtype: object"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 157/157 [00:46<00:00,  3.34it/s]\n100%|██████████| 158/158 [00:26<00:00,  5.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14:\nTest ROC-AUC backbone: 0.808\nTest ROC-AUC full net: 0.800\nTest ROC-AUC by query length:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"query_len\n1    [0.788, 0.774]\n2    [0.783, 0.774]\n3    [0.841, 0.834]\ndtype: object"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 157/157 [00:47<00:00,  3.34it/s]\n100%|██████████| 158/158 [00:26<00:00,  5.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15:\nTest ROC-AUC backbone: 0.813\nTest ROC-AUC full net: 0.805\nTest ROC-AUC by query length:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"query_len\n1    [0.791, 0.779]\n2    [0.788, 0.779]\n3    [0.844, 0.838]\ndtype: object"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 150268/150268 [12:03<00:00, 207.59it/s]\n100%|██████████| 6173/6173 [12:41<00:00,  8.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Done\n\n#    Model      MAP@10    MAP@50    NDCG@10    NDCG@50\n---  -------  --------  --------  ---------  ---------\na    run_1        0.09      0.11      0.158      0.175\n\nCPU times: user 51min 51s, sys: 8min 57s, total: 1h 49s\nWall time: 45min 24s\n","output_type":"stream"}]},{"cell_type":"code","source":"model.backbone.save_pretrained('model_tuned/')\nmodel.tokenizer.save_pretrained('model_tuned/')\n\ntorch.save(model, 'model_tuned/model_tuned_full.pkl')\n\nshutil.make_archive('model_tuned', 'zip', 'model_tuned/')","metadata":{"execution":{"iopub.status.busy":"2023-06-06T21:28:20.305945Z","iopub.execute_input":"2023-06-06T21:28:20.309157Z","iopub.status.idle":"2023-06-06T21:28:37.330830Z","shell.execute_reply.started":"2023-06-06T21:28:20.309087Z","shell.execute_reply":"2023-06-06T21:28:37.329383Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/model_tuned.zip'"},"metadata":{}}]},{"cell_type":"code","source":"model = torch.load('model_tuned/model_tuned_full.pkl', map_location=device)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T21:28:37.332507Z","iopub.execute_input":"2023-06-06T21:28:37.333608Z","iopub.status.idle":"2023-06-06T21:28:37.537742Z","shell.execute_reply.started":"2023-06-06T21:28:37.333554Z","shell.execute_reply":"2023-06-06T21:28:37.536454Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"ProjectorModel(\n  (backbone): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(83828, 312, padding_idx=0)\n      (position_embeddings): Embedding(2048, 312)\n      (token_type_embeddings): Embedding(2, 312)\n      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=312, out_features=312, bias=True)\n              (key): Linear(in_features=312, out_features=312, bias=True)\n              (value): Linear(in_features=312, out_features=312, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=312, out_features=312, bias=True)\n              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=312, out_features=600, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=600, out_features=312, bias=True)\n            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=312, out_features=312, bias=True)\n              (key): Linear(in_features=312, out_features=312, bias=True)\n              (value): Linear(in_features=312, out_features=312, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=312, out_features=312, bias=True)\n              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=312, out_features=600, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=600, out_features=312, bias=True)\n            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=312, out_features=312, bias=True)\n              (key): Linear(in_features=312, out_features=312, bias=True)\n              (value): Linear(in_features=312, out_features=312, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=312, out_features=312, bias=True)\n              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=312, out_features=600, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=600, out_features=312, bias=True)\n            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=312, out_features=312, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (projection_head): Sequential(\n    (0): Linear(in_features=312, out_features=64, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}