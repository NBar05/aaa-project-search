## Оценка проекта до взятия в работу

### 1) Оценить потенциал проекта. Насколько важно решить задачу?

Для классифайда задача поиска кажется достаточно важной: нужно помогать как можно чаще сводить покупателей и продавцов. 
Потенциальные эффекты от улучшения релевантности выдачи запросу следующие:
1. рост числа удавшихся сделок: покупатель видит более релевантные варианты для покупки раньше
2. рост эффекта от партнёрских программ: мы как провайдер площадки для объявлений, можем либо выделять некоторые объявления, либо перемещать их в поиске чуть повыше, так или иначе эффект от этих действий будет значительнее, если мы будем иметь более корректную сортировку объявлений по релевантности
    - примечание: на самом деле, здесь нужно ещё уметь отличать SR и LR эффекты; как пример, в SR в случае сломанного поиска клиент будет долистывать до рекламного объявления слева и кликать на него, повышая конверсию перехода по нему (здесь я провожу аналогию со статьёй, кажется от Microsoft, где их сломанный поиск привёл к тому, что пользователи пролистывали в Х раз больше страниц, что привело к просмотру X раз больше рекламы, но, само собой, эффект от такого действия будет временный и в LR привёл бы к оттоку пользователей)
3. косвенно, любое улучшение сервиса приведёт к росту числа как покупателей (быстрее находят что надо), так и продавцов (их быстрее находят + партнёрские программы эффективнее/выгоднее для продавцов), что в свою очередь приведёт к росту выбора и обогащению нашей выборки для обучения, что в свою очередь… и так далее :)

Численную привязку к Авито сделать не вышло, но могу показать варианты, предложенные ChatGPT для демонстрации возможных численных эффектов от улучшения поиска на других компаниях (правда числа самому перепроверить так и не удалось):

![This is an image](/aaa-project-search/images/ChatGPT-suggestions.png)


### 2) Есть ли простое решение? Насколько оно решит задачу? Сложно ли поддерживать такое решение?

Запросы и объявления состоят из слов, поэтому можно сделать следующее:
1. сделать нормализацию (стеминг для скорости) и чистку от стоп-слов
2. найти bag-of-words вектора для них (обучив CountVectorizer условный)
3. посчитать косинусную близость между ними и отсортировать по этим значениям

Поддерживать такое решение кажется не очень сложно: вектора для обработанных объявлений можно сохранять и хранить в sparse таблице (за счёт sparse формата это всё кажется возможным), определение вектора для запроса с помощью предобученной модели будет достаточно быстрым, подсчёт косинусной метрики для всех объявлений должен быть вполне быстрым за счёт разреженности векторов + возможной параллелизации вычислений

Проблемы здесь есть, как минимум прийдут на ум все, часто выделяемые в NLP + происходит недоучёт прочих характеристик как пользователя так и клиента + недоучёт взаимодействия между запросами и выдачей (по сути предлагаемому методу не нужен собранный таргет).


### 3) Реалистичность решения проблемы с помощью машинного обучения.

Проблема поиска уже довольно стара, к примеру все поисковики её в какой-то мере уже решили (но нет предела совершенству), например, Google, Yandex, Bing (который возможно реанимируют с помощью ChatGPT интеграции). Если рассматривать более релевантные Авито компании, можно поискать решения от Amazon, Alibaba, AliExpress, Ozon, Yandex Market… кажется, погуглив статьи и ютуб ролики от этих компаний, можно закопаться в этой задаче на большой срок. Но нужно учитывать и технические ограничения (например, вряд ли можно позволить себе все решения, предлагаемые в Google, масштабы работы и ресурсы сильно отличаются) и специфику бизнеса (из названных ранее компании я не упомянул ни одного классифайда, погуглив, найдётся/вспомнится более честный конкурент - Юлу). Если более конкретно, к задаче можно подступаться как к: 
- задаче классификации: на основе признаков пользователя и объявлений (скорее всего, предварительно отфильтрованных по набору правил) определяем релевантность/нерелевантность
- задаче metric learning: учимся релевантные пары запрос-выдача сближать, а нерелевантные отдалять
- задаче рекомендации: поиск тоже своего рода набор рекомендаций, где чем мы точнее, тем лучше

Во всех случаях feature engineering будет играть важную роль (тем же нейросетям, несмотря на их способность выделать нужное самим, можно и нужно подавать полезную информацию сразу на вход).
